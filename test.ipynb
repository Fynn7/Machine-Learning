{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fynns_tool_model import *\n",
    "\n",
    "\n",
    "# df = pd.DataFrame({'taste': ['Sweet', 'Sweet', 'Sour', 'Sweet', None,'Sour'], 'size': [\n",
    "#                   'Big', 'Big', 'Small', 'Medium',np.nan, 'Small'], 'int_size': [7, 8, 2, np.nan,4, 2], 'color': ['Red', 'Green', 'Green','Green', 'Red', 'Green']})\n",
    "# Xcols = list(set(df.columns)-set(['color']))\n",
    "# m = Model(df[Xcols],df['color'])\n",
    "# m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has automatically set to RandomForestRegressor since you didn't input model name.\n",
      "\n",
      "        Model: RandomForestRegressor\n",
      "        Model Arguments: {'n_estimators': 100}\n",
      "        MAE Score: 0.07286713286713287\n",
      "            \n",
      "X initiallized/updated.\n",
      "y initiallized/updated.\n",
      "modelArgs initiallized/updated.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "data=load_breast_cancer()\n",
    "X=data.data\n",
    "y=data.target\n",
    "m=Model(X,y,n_estimators=100) # directly input a RandomForestRegressor function argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no categorical columns in this dataset.\n",
      " So you don't need Encoder.\n"
     ]
    }
   ],
   "source": [
    "m.oe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================\n",
      "X:\n",
      "---------------------\n",
      "        0      1       2       3        4        5        6        7       8    \n",
      "0    17.99  10.38  122.80  1001.0  0.11840  0.27760  0.30010  0.14710  0.2419  \\\n",
      "1    20.57  17.77  132.90  1326.0  0.08474  0.07864  0.08690  0.07017  0.1812   \n",
      "2    19.69  21.25  130.00  1203.0  0.10960  0.15990  0.19740  0.12790  0.2069   \n",
      "3    11.42  20.38   77.58   386.1  0.14250  0.28390  0.24140  0.10520  0.2597   \n",
      "4    20.29  14.34  135.10  1297.0  0.10030  0.13280  0.19800  0.10430  0.1809   \n",
      "..     ...    ...     ...     ...      ...      ...      ...      ...     ...   \n",
      "564  21.56  22.39  142.00  1479.0  0.11100  0.11590  0.24390  0.13890  0.1726   \n",
      "565  20.13  28.25  131.20  1261.0  0.09780  0.10340  0.14400  0.09791  0.1752   \n",
      "566  16.60  28.08  108.30   858.1  0.08455  0.10230  0.09251  0.05302  0.1590   \n",
      "567  20.60  29.33  140.10  1265.0  0.11780  0.27700  0.35140  0.15200  0.2397   \n",
      "568   7.76  24.54   47.92   181.0  0.05263  0.04362  0.00000  0.00000  0.1587   \n",
      "\n",
      "          9   ...      20     21      22      23       24       25      26   \n",
      "0    0.07871  ...  25.380  17.33  184.60  2019.0  0.16220  0.66560  0.7119  \\\n",
      "1    0.05667  ...  24.990  23.41  158.80  1956.0  0.12380  0.18660  0.2416   \n",
      "2    0.05999  ...  23.570  25.53  152.50  1709.0  0.14440  0.42450  0.4504   \n",
      "3    0.09744  ...  14.910  26.50   98.87   567.7  0.20980  0.86630  0.6869   \n",
      "4    0.05883  ...  22.540  16.67  152.20  1575.0  0.13740  0.20500  0.4000   \n",
      "..       ...  ...     ...    ...     ...     ...      ...      ...     ...   \n",
      "564  0.05623  ...  25.450  26.40  166.10  2027.0  0.14100  0.21130  0.4107   \n",
      "565  0.05533  ...  23.690  38.25  155.00  1731.0  0.11660  0.19220  0.3215   \n",
      "566  0.05648  ...  18.980  34.12  126.70  1124.0  0.11390  0.30940  0.3403   \n",
      "567  0.07016  ...  25.740  39.42  184.60  1821.0  0.16500  0.86810  0.9387   \n",
      "568  0.05884  ...   9.456  30.37   59.16   268.6  0.08996  0.06444  0.0000   \n",
      "\n",
      "         27      28       29  \n",
      "0    0.2654  0.4601  0.11890  \n",
      "1    0.1860  0.2750  0.08902  \n",
      "2    0.2430  0.3613  0.08758  \n",
      "3    0.2575  0.6638  0.17300  \n",
      "4    0.1625  0.2364  0.07678  \n",
      "..      ...     ...      ...  \n",
      "564  0.2216  0.2060  0.07115  \n",
      "565  0.1628  0.2572  0.06637  \n",
      "566  0.1418  0.2218  0.07820  \n",
      "567  0.2650  0.4087  0.12400  \n",
      "568  0.0000  0.2871  0.07039  \n",
      "\n",
      "[569 rows x 30 columns]\n",
      "\n",
      "==========================================\n",
      "y:\n",
      "---------------------\n",
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "564    0\n",
      "565    0\n",
      "566    0\n",
      "567    0\n",
      "568    1\n",
      "Length: 569, dtype: int32\n",
      "\n",
      "==========================================\n",
      "df:\n",
      "---------------------\n",
      "      0.0    1.0     2.0     3.0      4.0      5.0      6.0      7.0     8.0    \n",
      "0    17.99  10.38  122.80  1001.0  0.11840  0.27760  0.30010  0.14710  0.2419  \\\n",
      "1    20.57  17.77  132.90  1326.0  0.08474  0.07864  0.08690  0.07017  0.1812   \n",
      "2    19.69  21.25  130.00  1203.0  0.10960  0.15990  0.19740  0.12790  0.2069   \n",
      "3    11.42  20.38   77.58   386.1  0.14250  0.28390  0.24140  0.10520  0.2597   \n",
      "4    20.29  14.34  135.10  1297.0  0.10030  0.13280  0.19800  0.10430  0.1809   \n",
      "..     ...    ...     ...     ...      ...      ...      ...      ...     ...   \n",
      "564  21.56  22.39  142.00  1479.0  0.11100  0.11590  0.24390  0.13890  0.1726   \n",
      "565  20.13  28.25  131.20  1261.0  0.09780  0.10340  0.14400  0.09791  0.1752   \n",
      "566  16.60  28.08  108.30   858.1  0.08455  0.10230  0.09251  0.05302  0.1590   \n",
      "567  20.60  29.33  140.10  1265.0  0.11780  0.27700  0.35140  0.15200  0.2397   \n",
      "568   7.76  24.54   47.92   181.0  0.05263  0.04362  0.00000  0.00000  0.1587   \n",
      "\n",
      "        9.0   ...   21.0    22.0    23.0     24.0     25.0    26.0    27.0   \n",
      "0    0.07871  ...  17.33  184.60  2019.0  0.16220  0.66560  0.7119  0.2654  \\\n",
      "1    0.05667  ...  23.41  158.80  1956.0  0.12380  0.18660  0.2416  0.1860   \n",
      "2    0.05999  ...  25.53  152.50  1709.0  0.14440  0.42450  0.4504  0.2430   \n",
      "3    0.09744  ...  26.50   98.87   567.7  0.20980  0.86630  0.6869  0.2575   \n",
      "4    0.05883  ...  16.67  152.20  1575.0  0.13740  0.20500  0.4000  0.1625   \n",
      "..       ...  ...    ...     ...     ...      ...      ...     ...     ...   \n",
      "564  0.05623  ...  26.40  166.10  2027.0  0.14100  0.21130  0.4107  0.2216   \n",
      "565  0.05533  ...  38.25  155.00  1731.0  0.11660  0.19220  0.3215  0.1628   \n",
      "566  0.05648  ...  34.12  126.70  1124.0  0.11390  0.30940  0.3403  0.1418   \n",
      "567  0.07016  ...  39.42  184.60  1821.0  0.16500  0.86810  0.9387  0.2650   \n",
      "568  0.05884  ...  30.37   59.16   268.6  0.08996  0.06444  0.0000  0.0000   \n",
      "\n",
      "       28.0     29.0  NaN   \n",
      "0    0.4601  0.11890     0  \n",
      "1    0.2750  0.08902     0  \n",
      "2    0.3613  0.08758     0  \n",
      "3    0.6638  0.17300     0  \n",
      "4    0.2364  0.07678     0  \n",
      "..      ...      ...   ...  \n",
      "564  0.2060  0.07115     0  \n",
      "565  0.2572  0.06637     0  \n",
      "566  0.2218  0.07820     0  \n",
      "567  0.4087  0.12400     0  \n",
      "568  0.2871  0.07039     1  \n",
      "\n",
      "[569 rows x 31 columns]\n",
      "\n",
      "==========================================\n",
      "Xtrain:\n",
      "---------------------\n",
      "         0      1       2      3        4        5        6         7    \n",
      "0    11.410  10.82   73.34  403.3  0.09373  0.06685  0.03512  0.026230  \\\n",
      "1    13.780  15.79   88.37  585.9  0.08817  0.06718  0.01055  0.009937   \n",
      "2    14.690  13.98   98.22  656.1  0.10310  0.18360  0.14500  0.063000   \n",
      "3    16.170  16.07  106.30  788.5  0.09880  0.14380  0.06651  0.053970   \n",
      "4    13.300  21.57   85.24  546.1  0.08582  0.06373  0.03344  0.024240   \n",
      "..      ...    ...     ...    ...      ...      ...      ...       ...   \n",
      "421  15.280  22.41   98.92  710.6  0.09057  0.10520  0.05375  0.032630   \n",
      "422  12.420  15.04   78.61  476.5  0.07926  0.03393  0.01053  0.011080   \n",
      "423  14.400  26.99   92.25  646.1  0.06995  0.05223  0.03476  0.017370   \n",
      "424   9.876  19.40   63.95  298.3  0.10050  0.09697  0.06154  0.030290   \n",
      "425  13.210  28.06   84.88  538.4  0.08671  0.06877  0.02987  0.032750   \n",
      "\n",
      "         8        9   ...     20     21      22     23      24       25   \n",
      "0    0.1667  0.06113  ...  12.82  15.97   83.74  510.5  0.1548  0.23900  \\\n",
      "1    0.1405  0.05848  ...  15.27  17.50   97.90  706.6  0.1072  0.10710   \n",
      "2    0.2086  0.07406  ...  16.46  18.34  114.10  809.2  0.1312  0.36350   \n",
      "3    0.1990  0.06572  ...  16.97  19.14  113.10  861.5  0.1235  0.25500   \n",
      "4    0.1815  0.05696  ...  14.20  29.20   92.94  621.2  0.1140  0.16670   \n",
      "..      ...      ...  ...    ...    ...     ...    ...     ...      ...   \n",
      "421  0.1727  0.06317  ...  17.80  28.03  113.80  973.1  0.1301  0.32990   \n",
      "422  0.1546  0.05754  ...  13.20  20.37   83.85  543.4  0.1037  0.07776   \n",
      "423  0.1707  0.05433  ...  15.40  31.98  100.40  734.6  0.1017  0.14600   \n",
      "424  0.1945  0.06322  ...  10.76  26.83   72.22  361.2  0.1559  0.23020   \n",
      "425  0.1628  0.05781  ...  14.37  37.17   92.48  629.6  0.1072  0.13810   \n",
      "\n",
      "          26       27      28       29  \n",
      "0    0.21020  0.08958  0.3016  0.08523  \n",
      "1    0.03517  0.03312  0.1859  0.06810  \n",
      "2    0.32190  0.11080  0.2827  0.09208  \n",
      "3    0.21140  0.12510  0.3153  0.08960  \n",
      "4    0.12120  0.05614  0.2637  0.06658  \n",
      "..       ...      ...     ...      ...  \n",
      "421  0.36300  0.12260  0.3175  0.09772  \n",
      "422  0.06243  0.04052  0.2901  0.06783  \n",
      "423  0.14720  0.05563  0.2345  0.06464  \n",
      "424  0.26440  0.09749  0.2622  0.08490  \n",
      "425  0.10620  0.07958  0.2473  0.06443  \n",
      "\n",
      "[426 rows x 30 columns]\n",
      "\n",
      "==========================================\n",
      "Xtest:\n",
      "---------------------\n",
      "         0      1       2       3        4        5        6        7    \n",
      "0    12.620  17.15   80.62   492.9  0.08583  0.05430  0.02966  0.02272  \\\n",
      "1    13.240  20.13   86.87   542.9  0.08284  0.12230  0.10100  0.02833   \n",
      "2     9.731  15.34   63.78   300.2  0.10720  0.15990  0.41080  0.07857   \n",
      "3    12.870  19.54   82.67   509.2  0.09136  0.07883  0.01797  0.02090   \n",
      "4    12.060  12.74   76.84   448.6  0.09311  0.05241  0.01972  0.01963   \n",
      "..      ...    ...     ...     ...      ...      ...      ...      ...   \n",
      "138  17.060  21.00  111.80   918.6  0.11190  0.10560  0.15080  0.09934   \n",
      "139  13.650  13.16   87.88   568.9  0.09646  0.08711  0.03888  0.02563   \n",
      "140   9.436  18.32   59.82   278.6  0.10090  0.05956  0.02710  0.01406   \n",
      "141  23.510  24.27  155.10  1747.0  0.10690  0.12830  0.23080  0.14100   \n",
      "142  11.850  17.46   75.54   432.7  0.08372  0.05642  0.02688  0.02280   \n",
      "\n",
      "         8        9   ...     20     21      22      23      24      25   \n",
      "0    0.1799  0.05826  ...  14.34  22.15   91.62   633.5  0.1225  0.1517  \\\n",
      "1    0.1601  0.06432  ...  15.44  25.50  115.00   733.5  0.1201  0.5646   \n",
      "2    0.2548  0.09296  ...  11.02  19.49   71.04   380.5  0.1292  0.2772   \n",
      "3    0.1861  0.06347  ...  14.45  24.38   95.14   626.9  0.1214  0.1652   \n",
      "4    0.1590  0.05907  ...  13.14  18.41   84.08   532.8  0.1275  0.1232   \n",
      "..      ...      ...  ...    ...    ...     ...     ...     ...     ...   \n",
      "138  0.1727  0.06071  ...  20.99  33.15  143.20  1362.0  0.1449  0.2053   \n",
      "139  0.1360  0.06344  ...  15.34  16.35   99.71   706.2  0.1311  0.2474   \n",
      "140  0.1506  0.06959  ...  12.02  25.02   75.79   439.6  0.1333  0.1049   \n",
      "141  0.1797  0.05506  ...  30.67  30.73  202.40  2906.0  0.1515  0.2678   \n",
      "142  0.1875  0.05715  ...  13.06  25.75   84.35   517.8  0.1369  0.1758   \n",
      "\n",
      "          26       27      28       29  \n",
      "0    0.18870  0.09851  0.3270  0.07330  \n",
      "1    0.65560  0.13570  0.2845  0.12490  \n",
      "2    0.82160  0.15710  0.3108  0.12590  \n",
      "3    0.07127  0.06384  0.3313  0.07735  \n",
      "4    0.08636  0.07025  0.2514  0.07898  \n",
      "..       ...      ...     ...      ...  \n",
      "138  0.39200  0.18270  0.2623  0.07599  \n",
      "139  0.17590  0.08056  0.2380  0.08718  \n",
      "140  0.11440  0.05052  0.2454  0.08136  \n",
      "141  0.48190  0.20890  0.2593  0.07738  \n",
      "142  0.13160  0.09140  0.3101  0.07007  \n",
      "\n",
      "[143 rows x 30 columns]\n",
      "\n",
      "==========================================\n",
      "ytrain:\n",
      "---------------------\n",
      "0      1\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      1\n",
      "      ..\n",
      "421    0\n",
      "422    1\n",
      "423    1\n",
      "424    1\n",
      "425    1\n",
      "Length: 426, dtype: int32\n",
      "\n",
      "==========================================\n",
      "ytest:\n",
      "---------------------\n",
      "0      1\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      1\n",
      "      ..\n",
      "138    0\n",
      "139    1\n",
      "140    1\n",
      "141    0\n",
      "142    1\n",
      "Length: 143, dtype: int32\n",
      "\n",
      "==========================================\n",
      "model:\n",
      "---------------------\n",
      "RandomForestRegressor\n",
      "\n",
      "==========================================\n",
      "modelArgs:\n",
      "---------------------\n",
      "{'n_estimators': 100}\n",
      "\n",
      "==========================================\n",
      "categoricalCols:\n",
      "---------------------\n",
      "[]\n",
      "\n",
      "==========================================\n",
      "numericCols:\n",
      "---------------------\n",
      "[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, nan]\n",
      "\n",
      "==========================================\n",
      "colsContainNaN:\n",
      "---------------------\n",
      "[]\n",
      "\n",
      "==========================================\n",
      "mae:\n",
      "---------------------\n",
      "0.07286713286713287\n",
      "\n",
      "==========================================\n"
     ]
    }
   ],
   "source": [
    "m.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has automatically set to RandomForestRegressor since you didn't input model name.\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Some arguments not found. \nOriginal Error Message:\n【RandomForestRegressor.__init__() got an unexpected keyword argument 'THIS_ARG_IT_SHOULD_NOT_BE_FOUND_AND_RAISE_MY_ERROR'】",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Fynn\\OneDrive\\_Docs\\CODING\\Machine Learning\\my_ml_models\\fynns_tool_model.py:497\u001b[0m, in \u001b[0;36mModel.mae\u001b[1;34m(self, random_state, inplace, **modelArgs)\u001b[0m\n\u001b[0;32m    496\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     m \u001b[39m=\u001b[39m \u001b[39meval\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00margsComm\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    498\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32m<string>:1\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: RandomForestRegressor.__init__() got an unexpected keyword argument 'THIS_ARG_IT_SHOULD_NOT_BE_FOUND_AND_RAISE_MY_ERROR'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Fynn\\OneDrive\\_Docs\\CODING\\Machine Learning\\my_ml_models\\test.ipynb 单元格 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Fynn/OneDrive/_Docs/CODING/Machine%20Learning/my_ml_models/test.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m m\u001b[39m=\u001b[39mModel(X,y,THIS_ARG_IT_SHOULD_NOT_BE_FOUND_AND_RAISE_MY_ERROR\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m) \u001b[39m# directly input a RandomForestRegressor function argument\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Fynn\\OneDrive\\_Docs\\CODING\\Machine Learning\\my_ml_models\\fynns_tool_model.py:280\u001b[0m, in \u001b[0;36mModel.__init__\u001b[1;34m(self, X, y, model, test_size, train_size, random_state, **modelArgs)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, X: pd\u001b[39m.\u001b[39mDataFrame, y: pd\u001b[39m.\u001b[39mSeries, model: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, test_size: \u001b[39mfloat\u001b[39m \u001b[39m|\u001b[39m \u001b[39mint\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, train_size: \u001b[39mfloat\u001b[39m \u001b[39m|\u001b[39m \u001b[39mint\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, random_state: \u001b[39mint\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodelArgs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[39m    ```\u001b[39;00m\n\u001b[0;32m    259\u001b[0m \u001b[39m    >>> from fynns_tool_model import *\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[39m    ```\u001b[39;00m\n\u001b[0;32m    279\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[1;32m--> 280\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minit(X, y, model\u001b[39m=\u001b[39;49mmodel, test_size\u001b[39m=\u001b[39;49mtest_size,\n\u001b[0;32m    281\u001b[0m               train_size\u001b[39m=\u001b[39;49mtrain_size, random_state\u001b[39m=\u001b[39;49mrandom_state,\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodelArgs)\n",
      "File \u001b[1;32mc:\\Users\\Fynn\\OneDrive\\_Docs\\CODING\\Machine Learning\\my_ml_models\\fynns_tool_model.py:384\u001b[0m, in \u001b[0;36mModel.init\u001b[1;34m(self, X, y, model, train_size, test_size, random_state, **modelArgs)\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[39mdel\u001b[39;00m dfcopy\n\u001b[0;32m    383\u001b[0m \u001b[39m# Mean Absolute Error score\u001b[39;00m\n\u001b[1;32m--> 384\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mae \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmae(random_state\u001b[39m=\u001b[39;49mrandom_state,\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodelArgs)\n\u001b[0;32m    386\u001b[0m \u001b[39m# pop out these names we don't expect: 'self','attrNames','attr'\u001b[39;00m\n\u001b[0;32m    387\u001b[0m attrNames \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minit\u001b[39m.\u001b[39m\u001b[39m__code__\u001b[39m\u001b[39m.\u001b[39mco_varnames)[\u001b[39m1\u001b[39m:\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Fynn\\OneDrive\\_Docs\\CODING\\Machine Learning\\my_ml_models\\fynns_tool_model.py:499\u001b[0m, in \u001b[0;36mModel.mae\u001b[1;34m(self, random_state, inplace, **modelArgs)\u001b[0m\n\u001b[0;32m    497\u001b[0m     m \u001b[39m=\u001b[39m \u001b[39meval\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00margsComm\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    498\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m--> 499\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mSome arguments not found. \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mOriginal Error Message:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m【\u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m】\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    500\u001b[0m \u001b[39m# !!! Avoid using eval and getattr for dynamic code execution: Instead of dynamically constructing and executing code strings, it's generally safer and more readable to directly call the methods and classes.\u001b[39;00m\n\u001b[0;32m    501\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;31mException\u001b[0m: Some arguments not found. \nOriginal Error Message:\n【RandomForestRegressor.__init__() got an unexpected keyword argument 'THIS_ARG_IT_SHOULD_NOT_BE_FOUND_AND_RAISE_MY_ERROR'】"
     ]
    }
   ],
   "source": [
    "m=Model(X,y,THIS_ARG_IT_SHOULD_NOT_BE_FOUND_AND_RAISE_MY_ERROR=100) # directly input a RandomForestRegressor function argument\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
