{"cells":[{"cell_type":"markdown","metadata":{},"source":["**This notebook is an exercise in the [Intermediate Machine Learning](https://www.kaggle.com/learn/intermediate-machine-learning) course.  You can reference the tutorial at [this link](https://www.kaggle.com/alexisbcook/pipelines).**\n","\n","---\n"]},{"cell_type":"markdown","metadata":{},"source":["In this exercise, you will use **pipelines** to improve the efficiency of your machine learning code.\n","\n","# Setup\n","\n","The questions below will give you feedback on your work. Run the following cell to set up the feedback system."]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# # Set up code checking\n","# import os\n","# if not os.path.exists(\"../input/train.csv\"):\n","#     os.symlink(\"../input/home-data-for-ml-course/train.csv\", \"../input/train.csv\")  \n","#     os.symlink(\"../input/home-data-for-ml-course/test.csv\", \"../input/test.csv\") \n","# from learntools.core import binder\n","# binder.bind(globals())\n","# from learntools.ml_intermediate.ex4 import *\n","# print(\"Setup Complete\")"]},{"cell_type":"markdown","metadata":{},"source":["You will work with data from the [Housing Prices Competition for Kaggle Learn Users](https://www.kaggle.com/c/home-data-for-ml-course). \n","\n","![Ames Housing dataset image](https://storage.googleapis.com/kaggle-media/learn/images/lTJVG4e.png)\n","\n","Run the next code cell without changes to load the training and validation sets in `X_train`, `X_valid`, `y_train`, and `y_valid`.  The test set is loaded in `X_test`."]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '../input/train.csv'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[1;32mc:\\Users\\Fynn\\OneDrive\\_Docs\\CODING\\Machine Learning\\kaggle\\exercise-pipelines.ipynb 单元格 5\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Fynn/OneDrive/_Docs/CODING/Machine%20Learning/kaggle/exercise-pipelines.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Fynn/OneDrive/_Docs/CODING/Machine%20Learning/kaggle/exercise-pipelines.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Read the data\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Fynn/OneDrive/_Docs/CODING/Machine%20Learning/kaggle/exercise-pipelines.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m X_full \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39m../input/train.csv\u001b[39;49m\u001b[39m'\u001b[39;49m, index_col\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mId\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Fynn/OneDrive/_Docs/CODING/Machine%20Learning/kaggle/exercise-pipelines.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m X_test_full \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39m../input/test.csv\u001b[39m\u001b[39m'\u001b[39m, index_col\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mId\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Fynn/OneDrive/_Docs/CODING/Machine%20Learning/kaggle/exercise-pipelines.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Remove rows with missing target, separate target from predictors\u001b[39;00m\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1662\u001b[0m     f,\n\u001b[0;32m   1663\u001b[0m     mode,\n\u001b[0;32m   1664\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1665\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1666\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1667\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1668\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1669\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n","\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/train.csv'"]}],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","# Read the data\n","X_full = pd.read_csv('../input/train.csv', index_col='Id')\n","X_test_full = pd.read_csv('../input/test.csv', index_col='Id')\n","\n","# Remove rows with missing target, separate target from predictors\n","X_full.dropna(axis=0, subset=['SalePrice'], inplace=True)\n","y = X_full.SalePrice\n","X_full.drop(['SalePrice'], axis=1, inplace=True)\n","\n","# Break off validation set from training data\n","X_train_full, X_valid_full, y_train, y_valid = train_test_split(X_full, y, \n","                                                                train_size=0.8, test_size=0.2,\n","                                                                random_state=0)\n","\n","# \"Cardinality\" means the number of unique values in a column\n","# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n","categorical_cols = [cname for cname in X_train_full.columns if\n","                    X_train_full[cname].nunique() < 10 and \n","                    X_train_full[cname].dtype == \"object\"]\n","\n","# Select numerical columns\n","numerical_cols = [cname for cname in X_train_full.columns if \n","                X_train_full[cname].dtype in ['int64', 'float64']]\n","\n","# Keep selected columns only\n","my_cols = categorical_cols + numerical_cols\n","X_train = X_train_full[my_cols].copy()\n","X_valid = X_valid_full[my_cols].copy()\n","X_test = X_test_full[my_cols].copy()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X_train.head()"]},{"cell_type":"markdown","metadata":{},"source":["The next code cell uses code from the tutorial to preprocess the data and train a model.  Run this code without changes."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_absolute_error\n","\n","# Preprocessing for numerical data\n","numerical_transformer = SimpleImputer(strategy='constant')\n","\n","# Preprocessing for categorical data\n","categorical_transformer = Pipeline(steps=[\n","    ('imputer', SimpleImputer(strategy='most_frequent')),\n","    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n","])\n","\n","# Bundle preprocessing for numerical and categorical data\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', numerical_transformer, numerical_cols),\n","        ('cat', categorical_transformer, categorical_cols)\n","    ])\n","\n","# Define model\n","model = RandomForestRegressor(n_estimators=100, random_state=0)\n","\n","# Bundle preprocessing and modeling code in a pipeline\n","clf = Pipeline(steps=[('preprocessor', preprocessor),\n","                      ('model', model)\n","                     ])\n","\n","# Preprocessing of training data, fit model \n","clf.fit(X=X_train, y=y_train)\n","\n","# Preprocessing of validation data, get predictions\n","preds = clf.predict(X=X_valid)\n","\n","print('MAE:', mean_absolute_error(y_true=y_valid, y_pred=preds))"]},{"cell_type":"markdown","metadata":{},"source":["The code yields a value around 17862 for the mean absolute error (MAE).  In the next step, you will amend the code to do better.\n","\n","# Step 1: Improve the performance\n","\n","### Part A\n","\n","Now, it's your turn!  In the code cell below, define your own preprocessing steps and random forest model.  Fill in values for the following variables:\n","- `numerical_transformer`\n","- `categorical_transformer`\n","- `model`\n","\n","To pass this part of the exercise, you need only define valid preprocessing steps and a random forest model."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Preprocessing for numerical data\n","numerical_transformer = SimpleImputer(\n","    strategy='most_frequent')  # Your code here\n","\n","# Preprocessing for categorical data\n","categorical_transformer = Pipeline(steps=[\n","    # “most_frequent”: replace missing using the most frequent value along each column. Can be used with strings or numeric data. If there is more than one such value, only the smallest is returned.\n","    ('imputer', SimpleImputer(strategy='most_frequent')),\n","    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n","]\n",")  # Your code here\n","\n","# Bundle preprocessing for numerical and categorical data\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', numerical_transformer, numerical_cols),\n","        ('cat', categorical_transformer, categorical_cols)\n","    ])\n","\n","# Define model\n","model = RandomForestRegressor() # Your code here\n","\n","# Check your answer\n","step_1.a.check()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Lines below will give you a hint or solution code\n","#step_1.a.hint()\n","#step_1.a.solution()"]},{"cell_type":"markdown","metadata":{},"source":["### Part B\n","\n","Run the code cell below without changes.\n","\n","To pass this step, you need to have defined a pipeline in **Part A** that achieves lower MAE than the code above.  You're encouraged to take your time here and try out many different approaches, to see how low you can get the MAE!  (_If your code does not pass, please amend the preprocessing steps and model in Part A._)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Bundle preprocessing and modeling code in a pipeline\n","my_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n","                              ('model', model)\n","                             ])\n","\n","# Preprocessing of training data, fit model \n","my_pipeline.fit(X_train, y_train)\n","\n","# Preprocessing of validation data, get predictions\n","preds = my_pipeline.predict(X_valid)\n","\n","# Evaluate the model\n","score = mean_absolute_error(y_valid, preds)\n","print('MAE:', score)\n","\n","# Check your answer\n","step_1.b.check()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Line below will give you a hint\n","#step_1.b.hint()"]},{"cell_type":"markdown","metadata":{},"source":["# Step 2: Generate test predictions\n","\n","Now, you'll use your trained model to generate predictions with the test data."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Preprocessing of test data, fit model\n","preds_test = ____ # Your code here\n","\n","# Check your answer\n","step_2.check()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Lines below will give you a hint or solution code\n","#step_2.hint()\n","#step_2.solution()"]},{"cell_type":"markdown","metadata":{},"source":["Run the next code cell without changes to save your results to a CSV file that can be submitted directly to the competition."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Save test predictions to file\n","output = pd.DataFrame({'Id': X_test.index,\n","                       'SalePrice': preds_test})\n","output.to_csv('submission.csv', index=False)"]},{"cell_type":"markdown","metadata":{},"source":["# Submit your results\n","\n","Once you have successfully completed Step 2, you're ready to submit your results to the leaderboard!  If you choose to do so, make sure that you have already joined the competition by clicking on the **Join Competition** button at [this link](https://www.kaggle.com/c/home-data-for-ml-course).  \n","1. Begin by clicking on the **Save Version** button in the top right corner of the window.  This will generate a pop-up window.  \n","2. Ensure that the **Save and Run All** option is selected, and then click on the **Save** button.\n","3. This generates a window in the bottom left corner of the notebook.  After it has finished running, click on the number to the right of the **Save Version** button.  This pulls up a list of versions on the right of the screen.  Click on the ellipsis **(...)** to the right of the most recent version, and select **Open in Viewer**.  This brings you into view mode of the same page. You will need to scroll down to get back to these instructions.\n","4. Click on the **Data** tab near the top of the screen.  Then, click on the file you would like to submit, and click on the **Submit** button to submit your results to the leaderboard.\n","\n","You have now successfully submitted to the competition!\n","\n","If you want to keep working to improve your performance, select the **Edit** button in the top right of the screen. Then you can change your code and repeat the process. There's a lot of room to improve, and you will climb up the leaderboard as you work.\n","\n","\n","# Keep going\n","\n","Move on to learn about [**cross-validation**](https://www.kaggle.com/alexisbcook/cross-validation), a technique you can use to obtain more accurate estimates of model performance!"]},{"cell_type":"markdown","metadata":{},"source":["---\n","\n","\n","\n","\n","*Have questions or comments? Visit the [course discussion forum](https://www.kaggle.com/learn/intermediate-machine-learning/discussion) to chat with other learners.*"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"}},"nbformat":4,"nbformat_minor":4}
